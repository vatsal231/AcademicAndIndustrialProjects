{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Mar  2 16:22:34 2019\n",
    "\n",
    "@author: vatsal\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#other needed classes\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel(\"CreditData_RareEvent.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for calculating loss and confusion matrix\n",
    "def binary_loss(y, y_predict, fp_cost, fn_cost, display=True):\n",
    "    loss = [0, 0] #False Neg Cost, False Pos Cost\n",
    "    conf_mat = [0, 0, 0, 0] #tn, fp, fn, tp\n",
    "    for j in range(len(y)):\n",
    "        if y[j]==0:\n",
    "            if y_predict[j]==0:\n",
    "                conf_mat[0] += 1 #True Negative\n",
    "            else:\n",
    "                conf_mat[1] += 1 #False Positive\n",
    "                loss[1] += fp_cost[j]\n",
    "        else:\n",
    "            if y_predict[j]==1:\n",
    "                conf_mat[3] += 1 #True Positive\n",
    "            else:\n",
    "                conf_mat[2] += 1 #False Negative\n",
    "                loss[0] += fn_cost[j]\n",
    "    if display:\n",
    "        fn_loss = loss[0]\n",
    "        fp_loss = loss[1]\n",
    "        total_loss = fn_loss + fp_loss\n",
    "        misc = conf_mat[1] + conf_mat[2]\n",
    "        misc = misc/len(y)\n",
    "        print(\"{:.<23s}{:10.4f}\".format(\"Misclassification Rate\", misc))\n",
    "        print(\"{:.<23s}{:10.0f}\".format(\"False Negative Loss\", fn_loss))\n",
    "        print(\"{:.<23s}{:10.0f}\".format(\"False Positive Loss\", fp_loss))\n",
    "        print(\"{:.<23s}{:10.0f}\".format(\"Total Loss\", total_loss))\n",
    "    return loss, conf_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the loss using the randomforest algorithm without performing the under sampling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Model using Entire Dataset and depth =  5\n",
      "Misclassification Rate.    0.0457\n",
      "False Negative Loss....         0\n",
      "False Positive Loss....    190757\n",
      "Total Loss.............    190757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Attribute Map for CreditData_RareEvent.xlsx, N=10,500\n",
    "df = pd.get_dummies(df, columns=[\"checking\", \"history\", \"coapp\", \"savings\", \"employed\", \"installp\", \"marital\", \"resident\", \"property\", \"other\", \"housing\", \"existcr\", \"job\"])\n",
    "df.shape\n",
    "df['good_bad'] = df['good_bad'].map({'bad': 0, 'good': 1})\n",
    "y=np.asarray(df['good_bad'])\n",
    "X = np.asarray(df.drop(columns='good_bad'))\n",
    "\n",
    "# Setup false positive and false negative costs for each transaction\n",
    "fp_cost = np.array(0.1*df['amount'])\n",
    "fn_cost = np.array(df['amount'])\n",
    "\n",
    "depth=[]\n",
    "Recall=[]\n",
    "Accuracy=[]\n",
    "Precision=[]\n",
    "F1=[]\n",
    "best_depth = 0\n",
    "max_f = 0\n",
    "for i in [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    depth = i\n",
    "    decmodel = RandomForestClassifier(max_depth=i)\n",
    "    recall = cross_val_score(estimator=decmodel, X=X, y=y, cv=10 ,scoring='recall')\n",
    "    precision = cross_val_score(estimator=decmodel, X=X, y=y, cv=10 ,scoring='precision')\n",
    "    f1=cross_val_score(estimator=decmodel, X=X, y=y, cv=10 ,scoring='f1')\n",
    "    accuracy=cross_val_score(estimator=decmodel, X=X, y=y, cv=10 ,scoring='accuracy')\n",
    "    decmodel_10 = cross_val_score(decmodel, X, y, scoring='f1', cv=10)\n",
    "    mean = decmodel_10.mean()\n",
    "    if mean > max_f:\n",
    "        max_f = mean\n",
    "        best_depth = i\n",
    "        best_lgr = decmodel\n",
    "answers=pd.DataFrame({'Depth':depth,'Recall':Recall,'Accuracy':Accuracy,'Precision':Precision,'F1':F1})    \n",
    "\n",
    "print(\"\\nDecision Tree Model using Entire Dataset and depth = \",best_depth)\n",
    "clf_model = best_lgr.fit(X,y)\n",
    "\n",
    "Y_pred=clf_model.predict(X)\n",
    "cm=confusion_matrix(y,Y_pred)\n",
    "loss,conf_mat = binary_loss(y,best_lgr.predict(X),\\\n",
    "fp_cost,fn_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above we got false positive loss as zero since all the observations were classified as negative as the availability of positive/defaulters of credit card are very less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the undersampling with different ratios and tuning the hyperparameters to check out best model producing the minimum loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Model using 50:50 RUS\n",
      "Best depth.............    1.20E+01\n",
      "Misclassification Rate.      0.1294\n",
      "False Negative Loss.... $ 4,832,932\n",
      "False Positive Loss.... $     1,124\n",
      "Total Loss............. $ 4,834,056 +/- $235,374\n",
      "\n",
      "Random Forest Model using 60:40 RUS\n",
      "Best depth.............    2.00E+00\n",
      "Misclassification Rate.      0.0770\n",
      "False Negative Loss.... $ 2,008,080\n",
      "False Positive Loss.... $   146,141\n",
      "Total Loss............. $ 2,154,221 +/- $363,074\n",
      "\n",
      "Random Forest Model using 70:30 RUS\n",
      "Best depth.............    2.00E+00\n",
      "Misclassification Rate.      0.0482\n",
      "False Negative Loss.... $   260,179\n",
      "False Positive Loss.... $   188,044\n",
      "Total Loss............. $   448,224 +/- $79,965\n",
      "\n",
      "Random Forest Model using 75:25 RUS\n",
      "Best depth.............    2.00E+00\n",
      "Misclassification Rate.      0.0474\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $   207,213\n",
      "Total Loss............. $   207,213 +/- $1,144\n",
      "\n",
      "Random Forest Model using 80:20 RUS\n",
      "Best depth.............    4.00E+00\n",
      "Misclassification Rate.      0.0442\n",
      "False Negative Loss.... $    23,955\n",
      "False Positive Loss.... $   176,041\n",
      "Total Loss............. $   199,996 +/- $22,195\n",
      "\n",
      "Random Forest Model using 85:15 RUS\n",
      "Best depth.............    1.00E+01\n",
      "Misclassification Rate.      0.0155\n",
      "False Negative Loss.... $    39,205\n",
      "False Positive Loss.... $    37,669\n",
      "Total Loss............. $    76,875 +/- $12,730\n",
      "\n",
      "Best RUS Ratio.........       85:15\n",
      "Best Depth.............    1.00E+01\n",
      "Lowest Loss............ $    76,875 +/- $12,730\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Setup 20 random number seeds for use in creating random samples\n",
    "np.random.seed(12345)\n",
    "max_seed = 2**16 - 1\n",
    "rand_val = np.random.randint(low=1, high=max_seed, size=10)\n",
    "# Ratios of Majority:Minority Events\n",
    "ratio = [ '50:50', '60:40', '70:30', '75:25', '80:20', '85:15' ]\n",
    "# Dictionaries contains number of minority and majority\n",
    "# events in each ratio sample where n_majority = ratio x n_minority\n",
    "rus_ratio = ({0:500, 1:500}, {0:500, 1:750}, {0:500, 1:1167}, \\\n",
    "{0:500, 1:1500},{0:500, 1:2000}, {0:500, 1:2834})\n",
    "\n",
    "# Best model is one that minimizes the loss\n",
    "c_list = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "min_loss = 1e64\n",
    "best_ratio = 0\n",
    "for k in range(len(rus_ratio)):\n",
    "    print(\"\\nRandom Forest Model using \" + ratio[k] + \" RUS\")\n",
    "    best_c = 0\n",
    "    min_loss_c = 1e64\n",
    "    for j in range(len(c_list)):\n",
    "        c = c_list[j]\n",
    "        fn_loss = np.zeros(len(rand_val))\n",
    "        fp_loss = np.zeros(len(rand_val))\n",
    "        misc = np.zeros(len(rand_val))\n",
    "        for i in range(len(rand_val)):\n",
    "            rus = RandomUnderSampler(ratio=rus_ratio[k], \\\n",
    "                                     random_state=rand_val[i], \\\n",
    "                                     return_indices=False, \\\n",
    "                                     replacement=False)\n",
    "            X_rus, y_rus = rus.fit_sample(X, y)\n",
    "            \n",
    "            \n",
    "            decmodel = RandomForestClassifier(max_depth=c)\n",
    "            decmodel.fit(X_rus, y_rus)\n",
    "            loss, conf_mat = binary_loss(y, decmodel.predict(X), \\\n",
    "                                                   fp_cost, fn_cost, display=False)\n",
    "            fn_loss[i] = loss[0]\n",
    "            fp_loss[i] = loss[1]\n",
    "            misc[i] = (conf_mat[1] + conf_mat[2])/y.shape[0]\n",
    "        avg_misc = np.average(misc)\n",
    "        t_loss = fp_loss+fn_loss\n",
    "        avg_loss = np.average(t_loss)\n",
    "        if avg_loss < min_loss_c:\n",
    "            min_loss_c = avg_loss\n",
    "            se_loss_c = np.std(t_loss)/math.sqrt(len(rand_val))\n",
    "            best_c = c\n",
    "            misc_c = avg_misc\n",
    "            fn_avg_loss = np.average(fn_loss)\n",
    "            fp_avg_loss = np.average(fp_loss)\n",
    "    if min_loss_c < min_loss:\n",
    "        min_loss = min_loss_c\n",
    "        se_loss = se_loss_c\n",
    "        best_ratio = k\n",
    "        best_reg = best_c\n",
    "    print(\"{:.<23s}{:12.2E}\".format(\"Best depth\", best_c))\n",
    "    print(\"{:.<23s}{:12.4f}\".format(\"Misclassification Rate\",misc_c))\n",
    "    print(\"{:.<23s} ${:10,.0f}\".format(\"False Negative Loss\",fn_avg_loss))\n",
    "    print(\"{:.<23s} ${:10,.0f}\".format(\"False Positive Loss\",fp_avg_loss))\n",
    "    print(\"{:.<23s} ${:10,.0f}{:5s}${:<,.0f}\".format(\"Total Loss\", \\\n",
    "             min_loss_c, \" +/- \", se_loss_c))\n",
    "print(\"\")\n",
    "print(\"{:.<23s}{:>12s}\".format(\"Best RUS Ratio\", ratio[best_ratio]))\n",
    "print(\"{:.<23s}{:12.2E}\".format(\"Best Depth\", best_reg))\n",
    "print(\"{:.<23s} ${:10,.0f}{:5s}${:<,.0f}\".format(\"Lowest Loss\", \\\n",
    "min_loss, \" +/-\", se_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Estimates based on averaging 100 Models\n",
      "Misclassification Rate.    0.0000\n",
      "False Negative Loss....         0\n",
      "False Positive Loss....         0\n",
      "Total Loss.............         0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensemble Modeling - Averaging Classification Probabilities\n",
    "n_obs = len(y)\n",
    "n_rand = 100\n",
    "predicted_prob = np.zeros((n_obs,n_rand))\n",
    "avg_prob = np.zeros(n_obs)\n",
    "# Setup 100 random number seeds for use in creating random samples\n",
    "np.random.seed(12345)\n",
    "max_seed = 2**16 - 1\n",
    "rand_value = np.random.randint(1, high=max_seed, size=n_rand)\n",
    "# Model 100 random samples, each with a 85:15 ratio\n",
    "for i in range(len(rand_value)):\n",
    "    rus = RandomUnderSampler(ratio=rus_ratio[best_ratio], \\\n",
    "                             random_state=rand_value[i], return_indices=False, \\\n",
    "                             replacement=False)\n",
    "    X_rus, y_rus = rus.fit_sample(X, y)\n",
    "    decmodel = RandomForestClassifier(max_depth=c)\n",
    "    decmodel.fit(X_rus, y_rus)\n",
    "    predicted_prob[0:n_obs, i] = decmodel.predict_proba(X)[0:n_obs, 0]\n",
    "for i in range(n_obs):\n",
    "    avg_prob[i] = np.mean(predicted_prob[i,0:n_rand])\n",
    "# Set y_pred equal to the predicted classification\n",
    "y_pred = avg_prob[0:n_obs] < 0.5\n",
    "y_pred.astype(np.int)\n",
    "# Calculate loss from using the ensemble predictions\n",
    "print(\"\\nEnsemble Estimates based on averaging\",len(rand_value), \"Models\")\n",
    "loss, conf_mat = binary_loss(y, y_pred, fp_cost, fn_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally developing the ensembled model for the selected under sampling ratio leads us with 0 miss-classifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
